###################################################################################
###################################################################################
###################################################################################
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, 3, 3, activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, 3, 3, activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(len(Y_data_train[0]), activation=(tf.nn.softmax)))#.shape[1]

epochs = 30
train acc = 1
test acc = 0.600370466709137

WITH padding
epochs = 30
train acc = 1
test acc = 0.5985820889472961
###################################################################################
###################################################################################
###################################################################################
A DEEPER MODEL

model = Sequential()
model.add(Conv2D(16, (3, 3), activation='relu', input_shape=input_shape, padding = "same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu', padding = "same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, 3, 3, activation='relu', padding="same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, 3, 3, activation='relu', padding="same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(len(Y_data_train[0]), activation=(tf.nn.softmax)))#.shape[1]

epochs = 30
train acc = 0.97
test acc = 0.6102701425552368

a bit more of overfit
epochs = 35
train acc = 0.984
test acc = 0.608928918838501
###################################################################################
###################################################################################
###################################################################################
EVEN DEEPER

model = Sequential()
model.add(Conv2D(8, (3, 3), activation='relu', input_shape=input_shape, padding = "same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(16, (3, 3), activation='relu', padding = "same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(32, (3, 3), activation='relu', padding = "same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, 3, 3, activation='relu', padding="same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, 3, 3, activation='relu', padding="same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dense(len(Y_data_train[0]), activation=(tf.nn.softmax)))#.shape[1]

epochs = 35
train acc = 0.95
test acc = 0.5483809113502502
###################################################################################
###################################################################################
###################################################################################
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding="same"))
model.add(Conv2D(32, 3, 3, activation='relu', padding="same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, 3, 3, activation='relu', padding="same"))
model.add(Conv2D(64, 3, 3, activation='relu', padding="same"))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, 3, 3, activation='relu', padding="same"))
model.add(Conv2D(128, 3, 3, activation='relu', padding="same"))
#model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dense(len(Y_data_train[0]), activation=(tf.nn.softmax)))#.shape[1]

epochs = 30
train acc = 
test acc = 

###################################################################################
###################################################################################
###################################################################################
